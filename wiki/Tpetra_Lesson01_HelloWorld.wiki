#summary Tpetra Lesson 01: Initialization of MPI (if enabled)

= Lesson topics =

The Tpetra package provides next-generation distributed sparse linear algebra.  It includes sparse matrices, vectors, and other linear algebra objects, along with computational kernels. This lesson shows the initialization you need to do in order to start using Tpetra.  This differs slightly, depending on whether you are writing a code from scratch, or introducing Tpetra into an existing code base.  We will cover both cases with an example code.

= Copyright and license =

Please consider every code example in this lesson to begin with the following copyright and license information.
{{{
// @HEADER
// ***********************************************************************
//
//          Tpetra: Templated Linear Algebra Services Package
//                 Copyright (2008) Sandia Corporation
//
// Under the terms of Contract DE-AC04-94AL85000 with Sandia Corporation,
// the U.S. Government retains certain rights in this software.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
// 1. Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright
// notice, this list of conditions and the following disclaimer in the
// documentation and/or other materials provided with the distribution.
//
// 3. Neither the name of the Corporation nor the names of the
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY SANDIA CORPORATION "AS IS" AND ANY
// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
// PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL SANDIA CORPORATION OR THE
// CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
// EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
// Questions? Contact Michael A. Heroux (maherou@sandia.gov)
//
// ************************************************************************
// @HEADER
}}}


= Initialization for a code written from scratch =

This section explains how to set up the distributed-memory parallel environment for using Tpetra, in a new code.  If you want to introduce Tpetra into an existing application, please see the next section.

Tpetra was written for distributed-memory parallel programming.  It uses  [http://en.wikipedia.org/wiki/Message_Passing_Interface MPI] (the Message Passing Interface) for this.  However, Tpetra will work correctly whether or not you have built Trilinos with MPI support.  It does so by interacting with MPI through an interface called `Teuchos::Comm`.  (If you are familiar with Epetra, this interface is analogous to `Epetra_Comm`.)  If MPI is enabled, then this wraps an MPI_Comm.  Otherwise, this is a "serial communicator" with one process, analogous to MPI_COMM_SELF.

Furthermore, Trilinos provides an MPI initialization interface, `Teuchos::GlobalMPISession`.  This calls MPI_Init and MPI_Finalize for you in an MPI build, and does not call them if you did not build Trilinos with MPI support.  The following code example shows how to initialize MPI (if available) and get a `Teuchos::Comm` corresponding to MPI_COMM_WORLD.

{{{
//
// Example of basic initialization for using Tpetra.
//
// Includes MPI initialization, getting a Teuchos::Comm communicator,
// and printing out Tpetra version information.
//

#include <Tpetra_DefaultPlatform.hpp>
#include <Tpetra_Version.hpp>
#include <Teuchos_GlobalMPISession.hpp>
#include <Teuchos_oblackholestream.hpp>

void
exampleRoutine (const Teuchos::RCP<const Teuchos::Comm<int> >& comm,
		std::ostream& out)
{
  // Print out the Tpetra software version information.
  out << Tpetra::version() << std::endl << std::endl;
}

int 
main (int argc, char *argv[]) 
{
  // These "using" declarations make the code more concise, in that
  // you don't have to write the namespace along with the class or
  // object name.  This is especially helpful with commonly used
  // things like std::endl or Teuchos::RCP.
  using std::endl;
  using Teuchos::Comm;
  using Teuchos::RCP;
  using Teuchos::rcp;

  // A "black hole stream" prints nothing.  It's like /dev/null in
  // Unix-speak.  The typical MPI convention is that only MPI Rank 0
  // is allowed to print anything.  We enforce this convention by
  // setting Rank 0 to use std::cout for output, but all other ranks
  // to use the black hole stream.  It's more concise and less error
  // prone than having to check the rank every time you want to print.
  Teuchos::oblackholestream blackHole;

  // Start up MPI, if using MPI.  Trilinos doesn't have to be built
  // with MPI; it's called a "serial" build if you build without MPI.
  // GlobalMPISession hides this implementation detail.
  //
  // Note the third argument.  If you pass GlobalMPISession the
  // address of an std::ostream, it will print a one-line status
  // message with the rank on each MPI process.  This may be
  // undesirable if running with a large number of MPI processes.
  // You can avoid printing anything here by passing in either 
  // NULL or the address of a Teuchos::oblackholestream.
  Teuchos::GlobalMPISession mpiSession (&argc, &argv, NULL);

  // Get a pointer to the communicator object representing
  // MPI_COMM_WORLD.  getDefaultPlatform.getComm() doesn't create a
  // new object every time you call it; it just returns the same
  // communicator each time.  Thus, you can call it anywhere and get
  // the same communicator.  (This is handy if you don't want to pass
  // a communicator around everywhere, though it's always better to
  // parameterize your algorithms on the communicator.)
  //
  // "Tpetra::DefaultPlatform" knows whether or not we built with MPI
  // support.  If we didn't build with MPI, we'll get a "communicator"
  // with size 1, whose only process has rank 0.
  RCP<const Comm<int> > comm = 
    Tpetra::DefaultPlatform::getDefaultPlatform().getComm();

  const int myRank = comm->getRank();
  const int numProcs = comm->getSize();

  // The stream to which to write output.  Only MPI Rank 0 gets to
  // write to stdout; the other MPI processes get a "black hole
  // stream" (see above).
  std::ostream& out = (myRank == 0) ? std::cout : blackHole;

  // We have a communicator and an output stream.
  // Let's do something with them!
  exampleRoutine (comm, out);

  // GlobalMPISession calls MPI_Finalize() in its destructor, if
  // appropriate.  You don't have to do anything here!  Just return
  // from main().  Isn't that helpful?
  return 0;
}
}}}

= Initialization for an existing MPI code =

Tpetra also works fine in an existing MPI code.  For this example, we assume that your code initializes MPI on its own by calling MPI_Init, and calls MPI_Finalize at the end.  It also must get an MPI_Comm (an MPI communicator) somewhere, either by using a predefined communicator such as MPI_COMM_WORLD, or by creating a new one.

{{{
//
// Example of basic initialization for using Tpetra in an existing application
//
// Includes getting a Teuchos::Comm communicator to wrap your MPI_Comm,
// and printing out Tpetra version information.
//

// Your code is an existing MPI code, so it presumably includes mpi.h directly.
#include <mpi.h>  
// ... Your other include files go here ... 
#include <Tpetra_DefaultMpiComm.hpp>
#include <Tpetra_DefaultPlatform.hpp>
#include <Tpetra_Version.hpp>
#include <Teuchos_oblackholestream.hpp>

void
exampleRoutine (const Teuchos::RCP<const Teuchos::Comm<int> >& comm,
		std::ostream& out)
{
  // Print out the Tpetra software version information.
  out << Tpetra::version() << std::endl << std::endl;
}

int 
main (int argc, char *argv[]) 
{
  // These "using" declarations make the code more concise, in that
  // you don't have to write the namespace along with the class or
  // object name.  This is especially helpful with commonly used
  // things like std::endl or Teuchos::RCP.
  using std::endl;
  using Teuchos::Comm;
  using Teuchos;:MpiComm;
  using Teuchos::opaqueWrapper;
  using Teuchos::RCP;
  using Teuchos::rcp;

  // We assume that your code calls MPI_Init.  It's bad form 
  // to ignore the error codes returned by MPI functions, but
  // we do so here for brevity.
  (void) MPI_Init (&argc, &argv);

  // This code takes the place of whatever you do to get an MPI_Comm.
  MPI_Comm yourComm = MPI_COMM_WORLD;

  // Get a pointer to the communicator object that encapsulates 
  // your communicator.  In a very, very recent version of Trilinos,
  // you may use the first line (commented out) instead of the 
  // second line below.  Both of these lines assume that you are
  // responsible for calling MPI_Comm_free on your MPI_Comm,
  // if necessary (it's not necessary for MPI_COMM_WORLD).
  //
  //RCP<const Comm<int> > comm = rcp (new MpiComm<int> (yourComm));
  RCP<const Comm<int> > comm = rcp (new MpiComm<int> (opaqueWrapper<MPI_Comm> (yourComm)));
  
  const int myRank = comm->getRank();
  const int numProcs = comm->getSize();

  // The stream to which to write output.  Only MPI Rank 0 gets to
  // write to stdout; the other MPI processes get a "black hole
  // stream" (see above).
  Teuchos::oblackholestream blackHole;
  std::ostream& out = (myRank == 0) ? std::cout : blackHole;

  // We have a communicator and an output stream.
  // Let's do something with them!
  exampleRoutine (comm, out);

  // If you need to call MPI_Comm_free on your MPI_Comm, now would
  // be the time to do so, before calling MPI_Finalize.  You may also 
  // automate this process; ask the tutorial presenter for more information.

  // Since you called MPI_Init, you are responsible for calling MPI_Finalize.
  (void) MPI_Finalize ();
  return 0;
}
}}}

= Initialization for an existing non-MPI code =

The first code example in this lesson uses !GlobalMPISession to initialize MPI.  Despite the name, in a non-MPI build of Trilinos, it does nothing.  Thus, if you built Trilinos with MPI disabled, you should feel free to invoke !GlobalMPISession in your `main` function.  However, if you are using a build of Trilinos that has MPI enabled, but you don't want to use MPI in your application, you should not use !GlobalMPISession.  Instead, you should create a !SerialComm directly as the "communicator."  The following example shows how to create a !SerialComm.

{{{
//
// Example of non-MPI initialization for using Tpetra in an existing application
//

// ... Your other include files go here ... 
#include <Tpetra_DefaultPlatform.hpp>
#include <Tpetra_DefaultSerialComm.hpp>
#include <Tpetra_Version.hpp>
#include <Teuchos_oblackholestream.hpp>

void
exampleRoutine (const Teuchos::RCP<const Teuchos::Comm<int> >& comm,
		std::ostream& out)
{
  // Print out the Tpetra software version information.
  out << Tpetra::version() << std::endl << std::endl;
}

int 
main (int argc, char *argv[]) 
{
  using std::endl;
  using Teuchos::Comm;
  using Teuchos;:SerialComm;
  using Teuchos::RCP;
  using Teuchos::rcp;

  // Make a "serial" (non-MPI) communicator.
  // It doesn't actually "communicate," because it only has one process.
  RCP<const Comm<int> > comm = rcp (new SerialComm<int>);
  
  // With a "serial" communicator, the rank is always 0, 
  // and the number of processes is always 1.
  const int myRank = comm->getRank();
  const int numProcs = comm->getSize();

  Teuchos::oblackholestream blackHole;
  std::ostream& out = (myRank == 0) ? std::cout : blackHole;

  // We have a communicator and an output stream.
  // Let's do something with them!
  exampleRoutine (comm, out);

  return 0;
}
}}}

= Things we didn't explain above =

== What are RCP and rcp? ==

RCP stands for "reference-counted pointer."  It lives in the Teuchos package of Trilinos, and is Trilinos' version of std::shared_ptr or boost::shared_ptr.  (There are both historical and technical reasons why we use our own class instead of one of those.)  For more details, please refer to the [http://www.cs.sandia.gov/~rabartl/TeuchosMemoryManagementSAND.pdf complete reference] for the Teuchos memory management classes.

In brief: RCP lets you have the benefits of pointers (the lightweight sharing of data) without the headaches and risks (managing ownership and deallocation).  It behaves like a pointer in terms of syntax, but handles deallocation for you.  RCP is templated on the type of object to which it points.  For example, `RCP<T> x` works very much like `T* x` (a pointer to a `T`), and `RCP<const T> y` works like `const T* y` (that is, a "pointer to a `const T`").  The dereference (`*`) and method call (`->`) operators work just like they do with regular pointers.  For example, 
{{{
// Pointer to nonconst T.
RCP<T> x_ptr = ...;
// Unary operator* returns a reference, not a copy.
T& x_ref = *x_ptr;
x_ptr->nonconstInstanceMethod ();
x_ptr->constInstanceMethod ();

// Pointer to const T.
RCP<const T> y_ptr = ...;
const T& y_ref = *y_ptr;
// You may only call const instance methods with a const pointer.
y_ptr->constInstanceMethod ();
}}}
The "reference-counted" part of RCP means that it automatically handles deallocation, if appropriate.  Copying the RCP increments the reference count; allowing it to fall out of scope or assigning `Teuchos::null` to it decrements the reference count.  When the reference count reaches zero, the deallocation function is called.  By default, it calls `delete`, but you can control this behavior.  Reference counting allows you to share pointers between different parts of your code, without needing to worry about what part of the code deallocates the object, or when it gets deallocated.

The `rcp` function is a "nonmember constructor" template function that returns a newly created RCP of something.  Using `rcp` to create an RCP saves some typing, and also may improve exception safety.

== Comm, !MpiComm, and !SerialComm ==

Comm is Trilinos' interface to distributed-memory parallel communication.  It lives in the Teuchos package of Trilinos.  Comm is an abstract base class.  The !MpiComm and !SerialComm classes implement this interface.  As the name indicates, !MpiComm implements Comm by using MPI calls.  !SerialComm implements Comm without MPI, as a "communicator" with only one process.  (This is more or less equivalent to MPI_COMM_SELF, except without actually using MPI.)  All of these classes are templated on the integer type used for MPI function calls.  Currently, this is always `int`, so you should always use `int` as the template parameter.  

Since Comm is an abstract base class, you must handle it by pointer or reference.  The idiomatic way to create and handle a Comm is by RCP, as an `RCP<const Comm<int> >`.  This expression should be considered Trilinos' version of the `MPI_Comm` opaque handle.  Thus,
{{{
RCP<const Comm<int> > comm = rcp (new MpiComm<int> (MPI_COMM_WORLD));
}}}
is "Trilinos-speak" for this:
{{{
MPI_Comm comm = MPI_COMM_WORLD;
}}}

The normal way to use Comm is to call the nonmember functions in `Teuchos_CommHelpers.hpp`.  We won't cover this in the lesson today.